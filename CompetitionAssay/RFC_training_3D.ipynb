{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f51f9f2d",
   "metadata": {},
   "source": [
    "# Now work with the GT to train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8d1840f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.io import imread\n",
    "import os\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1d2d52f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = '../data_3D/'\n",
    "channel_name = \"green\" # rename it to WT or wsp or whatever mutant\n",
    "model_directory = \"../models/RFC_3D/\"\n",
    "\n",
    "\n",
    "# Now go through all existing GT files that contain non-zero pixels\n",
    "all_filenames = os.listdir(data_dir + channel_name + \"GT\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "liberal-monster",
   "metadata": {
    "id": "liberal-monster",
    "outputId": "9ab5e9d7-1c36-4c37-bec9-ab69c39289a0"
   },
   "outputs": [],
   "source": [
    "from skimage import filters\n",
    "\n",
    "def generate_feature_stack(image):\n",
    "    # determine features\n",
    "    blurred = filters.gaussian(image, sigma=2)\n",
    "    edges = filters.sobel(blurred)\n",
    "\n",
    "    # collect features in a stack\n",
    "    # The ravel() function turns a nD image into a 1-D image.\n",
    "    # We need to use it because scikit-learn expects values in a 1-D format here.\n",
    "    feature_stack = [\n",
    "        image.ravel(),\n",
    "        blurred.ravel(),\n",
    "        edges.ravel()\n",
    "    ]\n",
    "\n",
    "    # return stack as numpy-array\n",
    "    return np.asarray(feature_stack)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "painful-english",
   "metadata": {
    "id": "painful-english"
   },
   "source": [
    "## Formating data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "plastic-botswana",
   "metadata": {
    "id": "plastic-botswana",
    "outputId": "0516f370-4779-4fa0-b537-dba5ac615b2d"
   },
   "outputs": [],
   "source": [
    "def format_data(feature_stack, annotation):\n",
    "    # reformat the data to match what scikit-learn expects\n",
    "    # transpose the feature stack\n",
    "    X = feature_stack.T\n",
    "    # make the annotation 1-dimensional\n",
    "    y = annotation.ravel()\n",
    "\n",
    "    # remove all pixels from the feature and annotations which have not been annotated\n",
    "    mask = y > 0\n",
    "    X = X[mask]\n",
    "    y = y[mask]\n",
    "\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a509b661",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# in case you have not much memory as I do, you should run only one channel_name at a time\n",
    "\n",
    "X_stack = []\n",
    "y_stack = []\n",
    "\n",
    "for fn in all_filenames:\n",
    "    print(fn)\n",
    "\n",
    "    # load img and annotation\n",
    "    img = imread(data_dir + channel_name + \"/RAW/\" + fn)\n",
    "    annotation = imread(data_dir + channel_name + \"/GT/\" + fn)\n",
    "    \n",
    "    # prepare data for training\n",
    "    feature_stack = generate_feature_stack(img)\n",
    "    X, y = format_data(feature_stack, annotation)\n",
    "    del img, annotation, feature_stack\n",
    "       \n",
    "    X_stack.append(X)\n",
    "    y_stack.append(y)\n",
    "\n",
    "    # delete variables to save memory\n",
    "    del X, y\n",
    "    \n",
    "X_stack = np.concatenate(X_stack)\n",
    "y_stack = np.concatenate(y_stack)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c119072c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#detect inf values and set them to false\n",
    "mask = X_stack != np.inf \n",
    "# count if all 3 columns are True (or not)\n",
    "mask = np.sum(mask,axis=1) > 2\n",
    "\n",
    "X_stack = X_stack[mask,:]\n",
    "y_stack = y_stack[mask]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "crude-figure",
   "metadata": {
    "id": "crude-figure"
   },
   "source": [
    "# Training begins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b10e2645",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'model_for_3D_data.pkl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1613ee9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train classifier if not trained yet\n",
    "classifier = RandomForestClassifier()\n",
    "\n",
    "param_grid = {\n",
    "    'n_estimators': [50,100],  # Vary the number of trees\n",
    "    'max_depth': [2, 3],       # Vary the maximum depth of trees\n",
    "}\n",
    "\n",
    "\n",
    "grid_search = GridSearchCV(classifier, param_grid, cv=5)\n",
    "grid_search.fit(X_stack, y_stack)  # X and y are your training data and labels, respectively\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19275c03",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = grid_search.cv_results_\n",
    "\n",
    "# Extract the mean scores and reshape them into a grid\n",
    "scores = np.array(results['mean_test_score']).reshape(len(param_grid['n_estimators']),\n",
    "                                                      len(param_grid['max_depth']))\n",
    "\n",
    "\n",
    "# Create a heatmap of the mean scores\n",
    "plt.imshow(scores, cmap='viridis', origin='lower')\n",
    "plt.colorbar(label='Mean Score')\n",
    "plt.xlabel('min_samples_split')\n",
    "plt.ylabel('max_depth')\n",
    "plt.title('Grid Search Mean Scores')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78ccaee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_classifier = grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd9b1652",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save classifier \n",
    "\n",
    "if not os.path.exists(\"../models\"):\n",
    "    os.makedirs(\"../models\")\n",
    "\n",
    "if not os.path.exists(model_directory):\n",
    "    os.makedirs(model_directory)\n",
    "\n",
    "\n",
    "pickle.dump(best_classifier, open(model_directory+filename, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d8a553b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b2ec2778",
   "metadata": {},
   "source": [
    "# Now go to the other notebook for prediction. "
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
