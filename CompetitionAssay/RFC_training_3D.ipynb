{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "suffering-festival",
   "metadata": {
    "id": "suffering-festival"
   },
   "source": [
    "# Pixel classification using Scikit image\n",
    "Pixel classification is a technique for assigning pixels to multiple classes. If there are two classes (object and background), we are talking about binarization. In this example we use a [random forest classifier](https://en.wikipedia.org/wiki/Random_forest) for pixel classification.\n",
    "\n",
    "See also\n",
    "* [Scikit-image random forest](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html)\n",
    "* [Classification of land cover by Chris Holden](https://ceholden.github.io/open-geo-tutorial/python/chapter_5_classification.html)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e6ac9ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install scikit-image\n",
    "# !pip install -U scikit-learn\n",
    "# !pip install \"napari[all]\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "extreme-papua",
   "metadata": {
    "id": "extreme-papua"
   },
   "outputs": [],
   "source": [
    "from skimage.io import imsave, imread\n",
    "import os\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ebeb8a6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1a685572",
   "metadata": {},
   "source": [
    "# Define input path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91fb3308",
   "metadata": {},
   "outputs": [],
   "source": [
    "# path to the folder containing the images of a certain channel\n",
    "\n",
    "filepath = '/media/eric/WD_Elements/EPFL-data/Lucas/'\n",
    "\n",
    "fn_orange = 'orange_20230920_AirGel_WTmSc_dwspFmN_mix_LAM02J-L_CIP_5.5hpi_23.5h.nd...el_WTmSc_dwspFmN_mix_LAM02J-L_CIP_5.5hpi_23.5h.nd2 (series 08) - C=1.tif'\n",
    "fn_green = 'green_20230920_AirGel_WTmSc_dwspFmN_mix_LAM02J-L_CIP_5.5hpi_23.5h.nd...el_WTmSc_dwspFmN_mix_LAM02J-L_CIP_5.5hpi_23.5h.nd2 (series 08) - C=0.tif'\n",
    "\n",
    "\n",
    "orange = filepath + fn_orange\n",
    "green = filepath + fn_green\n",
    "\n",
    "# if orange endswith .nd2 then import pims_nd2\n",
    "if orange.endswith('.nd2'):\n",
    "    !pip install pims_nd2\n",
    "    import pims_nd2 as pims\n",
    "\n",
    "else:\n",
    "    !pip install pims\n",
    "    import pims\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c577c147",
   "metadata": {},
   "outputs": [],
   "source": [
    "import napari\n",
    "%gui qt\n",
    "\n",
    "def Draw_and_Save(img,output_dir,output_fn):\n",
    "    viewer = napari.Viewer()\n",
    "    viewer.add_image(img)\n",
    "    labels = viewer.add_labels(np.zeros(img.shape,dtype='uint8'))\n",
    "\n",
    "    print(\"before block\")\n",
    "    viewer.show(block=True)\n",
    "\n",
    "    print(\"after block\")\n",
    "    # get the drawings first\n",
    "    manual_annotations = labels.data\n",
    "\n",
    "    # save the drawings\n",
    "    manual_labels_filename = output_dir + '/' + output_fn\n",
    "    imsave(manual_labels_filename, manual_annotations, check_contrast=False)\n",
    "    viewer.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28bdcde9",
   "metadata": {},
   "source": [
    "# Prepare GT and save it together with the image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55b907a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = '../data_3D/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88ebe093",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create output directory\n",
    "import os\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)\n",
    "\n",
    "if not os.path.exists(output_dir + \"orange\"):\n",
    "    os.makedirs(output_dir + \"orange/GT\")\n",
    "\n",
    "if not os.path.exists(output_dir + \"green\"):\n",
    "    os.makedirs(output_dir + \"green/GT\")\n",
    "\n",
    "if not os.path.exists(output_dir + \"orange/RAW\"):\n",
    "    os.makedirs(output_dir + \"orange/RAW\")\n",
    "\n",
    "if not os.path.exists(output_dir + \"green/RAW\"):\n",
    "    os.makedirs(output_dir + \"green/RAW\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26269504",
   "metadata": {},
   "outputs": [],
   "source": [
    "orange_seq = pims.open(orange)\n",
    "green_seq = pims.open(green)\n",
    "Z_slices = 19\n",
    "xdim = 1200\n",
    "ydim = 1200\n",
    "\n",
    "timestep = 0\n",
    "counter = 0\n",
    "for t, (img_o, img_g) in enumerate(zip(orange_seq,green_seq)):\n",
    "    \n",
    "\n",
    "    # iterate through all z slices and stack them together\n",
    "    if np.mod(t,Z_slices) == 0:\n",
    "        # prepare empty array with the same dtype as the first image\n",
    "        counter = 0\n",
    "        orange_zstack = np.zeros((Z_slices,xdim,ydim))\n",
    "        green_zstack = np.zeros((Z_slices,xdim,ydim))\n",
    "\n",
    "    orange_zstack[counter,:,:] = img_o\n",
    "    green_zstack[counter,:,:] = img_g\n",
    "\n",
    "    if np.mod(t,Z_slices) == Z_slices-1:\n",
    "        print(\"Timestep: \", timestep)\n",
    "\n",
    "        # now there is a 3D image stack of 19 slices\n",
    "        print(orange_zstack.shape)\n",
    "        print(green_zstack.shape)\n",
    "\n",
    "        # start napari, save GT and RAW images\n",
    "        # keep the basename of fn\n",
    "\n",
    "        print(fn_orange)\n",
    "        Draw_and_Save(orange_zstack, output_dir + \"orange/GT/\", 'T_'+str(timestep).zfill(3)+ '_' + fn_orange)\n",
    "        imsave(output_dir + \"orange/RAW/\" + 'T_'+str(timestep).zfill(3)+  '_' + fn_orange , orange_zstack,check_contrast=False)\n",
    "\n",
    "        Draw_and_Save(green_zstack, output_dir + \"green/GT/\", 'T_'+str(timestep).zfill(3)+ '_' + fn_green )\n",
    "        imsave(output_dir + \"green/RAW/\" + 'T_'+str(timestep).zfill(3) + '_' +  fn_green, green_zstack,check_contrast=False)\n",
    "\n",
    "\n",
    "        timestep += 1\n",
    "\n",
    "    counter += 1\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f51f9f2d",
   "metadata": {},
   "source": [
    "# Now work with the GT to train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1d2d52f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Now go through all existing GT files that contain non-zero pixels\n",
    "green_gt_fn = os.listdir(output_dir + \"green/GT\")\n",
    "orange_gt_fn = os.listdir(output_dir + \"orange/GT\")\n",
    "\n",
    "orange_gt_fn\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "touched-application",
   "metadata": {
    "id": "touched-application"
   },
   "source": [
    "## Generating a feature stack\n",
    "Pixel classifiers such as the random forest classifier takes multiple images as input. We typically call these images a feature stack because for every pixel exist now multiple values (features). In the following example we create a feature stack containing three features:\n",
    "* The original pixel value\n",
    "* The pixel value after a Gaussian blur\n",
    "* The pixel value of the Gaussian blurred image processed through a Sobel operator.\n",
    "\n",
    "Thus, we denoise the image and detect edges. All three images serve the pixel classifier to differentiate positive an negative pixels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "liberal-monster",
   "metadata": {
    "id": "liberal-monster",
    "outputId": "9ab5e9d7-1c36-4c37-bec9-ab69c39289a0"
   },
   "outputs": [],
   "source": [
    "from skimage import filters\n",
    "\n",
    "def generate_feature_stack(image):\n",
    "    # determine features\n",
    "    blurred = filters.gaussian(image, sigma=2)\n",
    "    edges = filters.sobel(blurred)\n",
    "\n",
    "    # collect features in a stack\n",
    "    # The ravel() function turns a nD image into a 1-D image.\n",
    "    # We need to use it because scikit-learn expects values in a 1-D format here.\n",
    "    feature_stack = [\n",
    "        image.ravel(),\n",
    "        blurred.ravel(),\n",
    "        edges.ravel()\n",
    "    ]\n",
    "\n",
    "    # return stack as numpy-array\n",
    "    return np.asarray(feature_stack)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "painful-english",
   "metadata": {
    "id": "painful-english"
   },
   "source": [
    "## Formating data\n",
    "We now need to format the input data so that it fits to what scikit learn expects. Scikit-learn asks for an array of shape (n, m) as input data and (n) annotations. n corresponds to number of pixels and m to number of features. In our case m = 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "plastic-botswana",
   "metadata": {
    "id": "plastic-botswana",
    "outputId": "0516f370-4779-4fa0-b537-dba5ac615b2d"
   },
   "outputs": [],
   "source": [
    "def format_data(feature_stack, annotation):\n",
    "    # reformat the data to match what scikit-learn expects\n",
    "    # transpose the feature stack\n",
    "    X = feature_stack.T\n",
    "    # make the annotation 1-dimensional\n",
    "    y = annotation.ravel()\n",
    "\n",
    "    # remove all pixels from the feature and annotations which have not been annotated\n",
    "    mask = y > 0\n",
    "    X = X[mask]\n",
    "    y = y[mask]\n",
    "\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a509b661",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# in case you have not much memory as I do, you should run only one channel at a time\n",
    "\n",
    "channels = ['orange', 'green']\n",
    "filename_array = [orange_gt_fn, green_gt_fn]\n",
    "\n",
    "\n",
    "# make this to a for loop later\n",
    "channel = channels[0]\n",
    "filenames = filename_array[0]\n",
    "\n",
    "X_stack = []\n",
    "y_stack = []\n",
    "\n",
    "for fn in filenames:\n",
    "    print(fn)\n",
    "\n",
    "    img = imread(output_dir + channel + \"/RAW/\" + fn)\n",
    "    annotation = imread(output_dir + channel + \"/GT/\" + fn)\n",
    "    feature_stack = generate_feature_stack(img)\n",
    "    X, y = format_data(feature_stack, annotation)\n",
    "       \n",
    "    X_stack.append(X)\n",
    "    y_stack.append(y)\n",
    "\n",
    "    # delete variables to save memory\n",
    "    del X, y, img, feature_stack\n",
    "    \n",
    "X_stack = np.concatenate(X_stack)\n",
    "y_stack = np.concatenate(y_stack)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a75313dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_stack.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4bebeae",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = X_stack != np.inf\n",
    "mask.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3abf8259",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_stack.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c119072c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove infinite values\n",
    "mask = X_stack != np.inf\n",
    "mask = np.sum(mask,axis=1) > 2\n",
    "mask.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c70d443d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_stack = X_stack[mask,:]\n",
    "y_stack = y_stack[mask]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "crude-figure",
   "metadata": {
    "id": "crude-figure"
   },
   "source": [
    "# Training begins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b10e2645",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'model_for_3D_data.pkl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1613ee9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train classifier if not trained yet\n",
    "classifier = RandomForestClassifier()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "param_grid = {\n",
    "    'n_estimators': [50,100],  # Vary the number of trees\n",
    "    'max_depth': [2, 3],       # Vary the maximum depth of trees\n",
    "}\n",
    "\n",
    "\n",
    "grid_search = GridSearchCV(classifier, param_grid, cv=5)\n",
    "grid_search.fit(X_stack, y_stack)  # X and y are your training data and labels, respectively\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16d5c01d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_stack.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19275c03",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = grid_search.cv_results_\n",
    "\n",
    "# Extract the mean scores and reshape them into a grid\n",
    "scores = np.array(results['mean_test_score']).reshape(len(param_grid['n_estimators']),\n",
    "                                                      len(param_grid['max_depth']))\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "# Create a heatmap of the mean scores\n",
    "plt.imshow(scores, cmap='viridis', origin='lower')\n",
    "plt.colorbar(label='Mean Score')\n",
    "plt.xlabel('min_samples_split')\n",
    "plt.ylabel('max_depth')\n",
    "plt.title('Grid Search Mean Scores')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78ccaee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_classifier = grid_search.best_estimator_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd9b1652",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save classifier \n",
    "import pickle\n",
    "model_directory = \"../models/RFC_3D/\"\n",
    "\n",
    "import os\n",
    "if not os.path.exists(\"../models\"):\n",
    "    os.makedirs(\"../models\")\n",
    "\n",
    "if not os.path.exists(model_directory):\n",
    "    os.makedirs(model_directory)\n",
    "\n",
    "\n",
    "pickle.dump(best_classifier, open(model_directory+filename, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d8a553b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b2ec2778",
   "metadata": {},
   "source": [
    "# Now go to the other notebook for prediction. "
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
