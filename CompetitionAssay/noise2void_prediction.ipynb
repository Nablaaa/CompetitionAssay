{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bnsreenu/python_for_microscopists/blob/master/293_denoising_RGB_images_using_deep%20learning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "5HugHL6Cqvzg"
      },
      "source": [
        "https://youtu.be/71wqPyapFGU"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "nW3YtTvxWqqj"
      },
      "source": [
        "This example is for training a Noise2Void denoising model using RGB images. Images need to be in lossless format (e.g., png or tiff). JPG format is not allowed if you're using the DataGenerator object but you can use skimage or other ibraries to load them. The same approach can be used for grey-scale images, for example SEM or CT images."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j0OUdazrRDMf",
        "outputId": "4b63326b-1d65-43f3-b34c-8289386971e0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tensorflow==2.12.0 in /usr/local/lib/python3.10/dist-packages (2.12.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.12.0) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.12.0) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.12.0) (23.5.26)\n",
            "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.12.0) (0.4.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.12.0) (0.2.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.12.0) (1.56.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.12.0) (3.8.0)\n",
            "Requirement already satisfied: jax>=0.3.15 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.12.0) (0.4.13)\n",
            "Requirement already satisfied: keras<2.13,>=2.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.12.0) (2.12.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.12.0) (16.0.0)\n",
            "Requirement already satisfied: numpy<1.24,>=1.22 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.12.0) (1.22.4)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.12.0) (3.3.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.12.0) (23.1)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.12.0) (3.20.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.12.0) (67.7.2)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.12.0) (1.16.0)\n",
            "Requirement already satisfied: tensorboard<2.13,>=2.12 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.12.0) (2.12.3)\n",
            "Requirement already satisfied: tensorflow-estimator<2.13,>=2.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.12.0) (2.12.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.12.0) (2.3.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.12.0) (4.7.1)\n",
            "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.12.0) (1.14.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.12.0) (0.32.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow==2.12.0) (0.40.0)\n",
            "Requirement already satisfied: ml-dtypes>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from jax>=0.3.15->tensorflow==2.12.0) (0.2.0)\n",
            "Requirement already satisfied: scipy>=1.7 in /usr/local/lib/python3.10/dist-packages (from jax>=0.3.15->tensorflow==2.12.0) (1.10.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow==2.12.0) (2.17.3)\n",
            "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow==2.12.0) (1.0.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow==2.12.0) (3.4.3)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow==2.12.0) (2.27.1)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow==2.12.0) (0.7.1)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow==2.12.0) (2.3.6)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow==2.12.0) (5.3.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow==2.12.0) (0.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow==2.12.0) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.13,>=2.12->tensorflow==2.12.0) (1.3.1)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow==2.12.0) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow==2.12.0) (2023.5.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow==2.12.0) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow==2.12.0) (3.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.13,>=2.12->tensorflow==2.12.0) (2.1.3)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow==2.12.0) (0.5.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.13,>=2.12->tensorflow==2.12.0) (3.2.2)\n",
            "Requirement already satisfied: n2v in /usr/local/lib/python3.10/dist-packages (0.3.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from n2v) (1.22.4)\n",
            "Requirement already satisfied: tifffile in /usr/local/lib/python3.10/dist-packages (from n2v) (2023.7.10)\n",
            "Requirement already satisfied: imagecodecs>=2020.2.18 in /usr/local/lib/python3.10/dist-packages (from n2v) (2023.7.10)\n",
            "Requirement already satisfied: csbdeep<0.8.0,>=0.7.2 in /usr/local/lib/python3.10/dist-packages (from n2v) (0.7.3)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from n2v) (8.4.0)\n",
            "Requirement already satisfied: ruamel.yaml>=0.16.10 in /usr/local/lib/python3.10/dist-packages (from n2v) (0.17.32)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from csbdeep<0.8.0,>=0.7.2->n2v) (1.10.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from csbdeep<0.8.0,>=0.7.2->n2v) (3.7.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from csbdeep<0.8.0,>=0.7.2->n2v) (1.16.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from csbdeep<0.8.0,>=0.7.2->n2v) (4.65.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from csbdeep<0.8.0,>=0.7.2->n2v) (23.1)\n",
            "Requirement already satisfied: ruamel.yaml.clib>=0.2.7 in /usr/local/lib/python3.10/dist-packages (from ruamel.yaml>=0.16.10->n2v) (0.2.7)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->csbdeep<0.8.0,>=0.7.2->n2v) (1.1.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->csbdeep<0.8.0,>=0.7.2->n2v) (0.11.0)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->csbdeep<0.8.0,>=0.7.2->n2v) (4.40.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->csbdeep<0.8.0,>=0.7.2->n2v) (1.4.4)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->csbdeep<0.8.0,>=0.7.2->n2v) (3.1.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->csbdeep<0.8.0,>=0.7.2->n2v) (2.8.2)\n"
          ]
        }
      ],
      "source": [
        "#Install the tensorflow library suggested by N2V.\n",
        "!pip install tensorflow==2.12.0\n",
        "!pip install n2v"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "P13MtXx-MFAV"
      },
      "source": [
        "# Mount Google Drive to have access to your data which you should store there"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wPAJfhbg973u",
        "outputId": "c519fae6-0ea9-4b62-c5cb-bd955800e19f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qRUF1zNmR4xi",
        "outputId": "2ca6403f-6cd0-44db-9d15-392346e04242"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2.12.0\n",
            "0.3.2\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "import n2v\n",
        "print(tf.__version__)\n",
        "print(n2v.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_1RLQa0XRhL-"
      },
      "outputs": [],
      "source": [
        "# We import all our dependencies.\n",
        "from n2v.models import N2VConfig, N2V\n",
        "import numpy as np\n",
        "from csbdeep.utils import plot_history\n",
        "from n2v.utils.n2v_utils import manipulate_val_data\n",
        "from n2v.internals.N2V_DataGenerator import N2V_DataGenerator\n",
        "\n",
        "from matplotlib import pyplot as plt\n",
        "import urllib\n",
        "import os\n",
        "import zipfile\n",
        "\n",
        "import ssl\n",
        "ssl._create_default_https_context = ssl._create_unverified_context\n",
        "\n",
        "# We import all our dependencies.\n",
        "from n2v.models import N2V\n",
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "from matplotlib.image import imread, imsave\n",
        "from csbdeep.io import save_tiff_imagej_compatible"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y92qNgnsStWU"
      },
      "outputs": [],
      "source": [
        "# We create our DataGenerator-object.\n",
        "# It will help us load data and extract patches for training and validation.\n",
        "datagen = N2V_DataGenerator()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "Ys7l6IOjAEJP"
      },
      "source": [
        "If you have many images stored in a directory, use load_imgs_from_directory method to load them into a list. Images can be of different sizes as we are capturing them into a list, not an array.\n",
        "<p>\n",
        "You can also use your favorite way of reading images (e.g., using skimage) sequentially and capturing them into a list that can be used as input to the network.\n",
        "<p>\n",
        "Note that the images need to be in float32 format. load_imgs_from_directory method converts images to float32 but if you use your own way of loading images, you need to make sure they are converted to float32."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def NormalizeImg(img):\n",
        "    \"\"\"Normalize img input by subtracting the mean\n",
        "    and dividing by std\"\"\"\n",
        "    img = img.astype(\"float32\")\n",
        "    img -= np.mean(img)\n",
        "    img /= np.std(img)\n",
        "\n",
        "    return img"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vCZ2IX6JOKR3"
      },
      "outputs": [],
      "source": [
        "def n2vDenoising(img, visualize=False, pass_it=False):\n",
        "    img_normalized = NormalizeImg(img)\n",
        "    if pass_it:\n",
        "        return img_normalized\n",
        "\n",
        "    # We import all our dependencies.\n",
        "    model_name = \"n2v_transwell\"\n",
        "    model_dir = \"/content/drive/MyDrive/Lucas-Drive-Foldername/Noise2Void/models\"\n",
        "    model = N2V(config=None, name=model_name, basedir=model_dir)\n",
        "\n",
        "    # change shape to (y,x, c=1)\n",
        "    img_normalized = np.expand_dims(img_normalized, axis=-1)\n",
        "\n",
        "    pred = model.predict(img_normalized, axes=\"YXC\")\n",
        "\n",
        "    if visualize:\n",
        "        fig, axs = plt.subplots(1, 2, figsize=(10, 10))\n",
        "\n",
        "        axs[0].imshow(img)\n",
        "        axs[0].set_title(\"input\")\n",
        "\n",
        "        axs[1].imshow(pred[:, :, 0])\n",
        "        axs[1].set_title(\"output\")\n",
        "\n",
        "        plt.show()\n",
        "\n",
        "    return pred[:, :, 0]  # return same shape as input\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EPh_0GsuPOAK"
      },
      "outputs": [],
      "source": [
        "def GetTranswellData(base_dir, competition, files_are_in):\n",
        "    different_assays_folders = [\n",
        "        file for file in os.listdir(base_dir + competition + files_are_in) if file.endswith(\".tif\")\n",
        "    ]\n",
        "\n",
        "    # get all files that start with WT_\n",
        "    WT_files = [file for file in different_assays_folders if file.startswith(\"WT_\")]\n",
        "\n",
        "    Mutant_files = [file for file in different_assays_folders if not file.startswith(\"WT_\")]\n",
        "\n",
        "    # sort the files\n",
        "    WT_files.sort()\n",
        "    Mutant_files.sort()\n",
        "\n",
        "    return WT_files, Mutant_files"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hFFe_sHBPdKV"
      },
      "outputs": [],
      "source": []
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "oC-mypEpVcAP"
      },
      "source": [
        "<h1>Denoising images using the trained model</h1>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F_y3df5VQ6sv"
      },
      "outputs": [],
      "source": [
        "# collect all data\n",
        "\n",
        "base_dir = \"/content/drive/MyDrive/Lucas-Drive-Foldername/dataset_competition_assays/\"\n",
        "\n",
        "competition = \"competition_2_WTmScarlet_dwspFmNeonGreen/\"\n",
        "files_are_in = \"TW_growth/\"\n",
        "\n",
        "\n",
        "\n",
        "input_dir = base_dir + competition + files_are_in\n",
        "output_dir = input_dir + \"denoised/\"\n",
        "\n",
        "# create output directory if it does not exist\n",
        "if not os.path.exists(output_dir):\n",
        "    os.makedirs(output_dir)\n",
        "\n",
        "# get all filenames\n",
        "WT_files, Mutant_files = GetTranswellData(\n",
        "    base_dir, competition, files_are_in\n",
        ")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "lYhhg_xMQ9iw"
      },
      "source": [
        "## Run the denoising script"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kp2RTEro-gLC",
        "outputId": "0245f0f9-078c-4df0-a6ee-0e88f790ca9b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "float32\n",
            "(250, 256, 256)\n"
          ]
        }
      ],
      "source": [
        "from skimage.io import imread,imsave\n",
        "# TODO: this is just mock code, because \"filenames\" does not exist yet and data should also be stored in the correct subfolders ideally\n",
        "for WT_fn, Mutant_fn in zip(WT_files, Mutant_files):\n",
        "\n",
        "\n",
        "    # process WT\n",
        "    img = imread(input_dir + WT_fn)\n",
        "    denoised_data = n2vDenoising(img, visualize=False, pass_it=False)\n",
        "    imsave(output_dir + WT_fn,denoised_data)\n",
        "\n",
        "    # process Mutant\n",
        "    img = imread(input_dir + Mutant_fn)\n",
        "    denoised_data = n2vDenoising(img, visualize=False, pass_it=False)\n",
        "    imsave(output_dir + Mutant_fn,denoised_data)\n",
        "\n",
        "\n",
        "\n",
        "print(\"The results are now in \" + output_dir + \" in your google drive\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xrvgfFS_WB4b"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
